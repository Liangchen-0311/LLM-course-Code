{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c72f12-dca7-4cdc-bb17-98ef486547bc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b8c2f",
   "metadata": {},
   "source": [
    "## What is agent\n",
    "\n",
    "“What was X corporation’s total revenue for FY 2022?”\n",
    "\n",
    "Now consider a question like, “What were the three takeaways from the Q2 earnings call from FY 23? Focus on the technological moats that the company is building”. \n",
    "\n",
    "This inquiry requires planning, tailored focus, memory, using different tools, and breaking down a complex question into simpler sub-parts.. These concepts assembled together are essentially what we have come to refer to as an LLM Agent.  \n",
    "\n",
    "---\n",
    "\n",
    "“X 公司在2022财年的总收入是多少？”\n",
    "\n",
    "现在再考虑这样一个问题：“从2023财年Q2盈利电话会议中得出的三个要点是什么？重点关注公司正在构建的技术壁垒。” \n",
    "\n",
    "这种查询需要规划、专注、记忆、使用不同工具，并将一个复杂问题分解为更简单的子部分。将这些概念组合在一起，基本上就形成了我们所谓的LLM Agent。\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "They combine thorough data analysis, strategic planning, data retrieval, and the ability to learn from past actions to solve complex issues.\n",
    "\n",
    "\n",
    "LLM agents are advanced AI systems designed for creating complex text that needs sequential reasoning. They can think ahead, remember past conversations, and use different tools to adjust their responses based on the situation and style needed.\n",
    "\n",
    "\n",
    "To complete these subtasks, the LLM agent requires a structured plan, a reliable memory to track progress, and access to necessary tools. These components form the backbone of an LLM agent’s workflow.\n",
    "\n",
    "---\n",
    "\n",
    "它们结合了深入的数据分析、战略规划、数据检索以及从过去行动中学习的能力来解决复杂问题。\n",
    "\n",
    "LLM Agent是专为需要推理的复杂文本而设计的AI系统。它们可以构思、记住历史对话，并使用不同的工具根据所需的情况和风格调整其回应。\n",
    "\n",
    "为了完成这些子任务，Agent需要一个结构化的计划，一个可靠的记忆来跟踪进展，并能够获取必要的工具。这些组件构成了Agent工作流程的支柱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b1a66-4859-4ee3-9ae6-743c93ecc8f7",
   "metadata": {},
   "source": [
    "## LLM agent components\n",
    "\n",
    "\n",
    "![](agent-overview.png)\n",
    "\n",
    "\n",
    "LLM agents generally consist of four components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc423563-672a-4f14-bfe0-6b95aa67ee80",
   "metadata": {},
   "source": [
    "### Agent/brain\n",
    "\n",
    "- define general goals of the agent: overall goals and objectives for the agent.\n",
    "- define tools for execution: Essentially a short list or a  “user manual” for all the tools to which the agent has access\n",
    "- define explanation for how to make use of different planning modules: Details about the utility of different planning modules and which to use in what situation.\n",
    "- define relevant memory: This is a dynamic section which fills the most relevant memory items from past conversations with the user at inference time. The “relevance” is determined using the question user asks.\n",
    "- define persona of the agent (optional): This persona description is typically used to either bias the model to prefer using certain types of tools or to imbue typical idiosyncrasies in the agent’s final response. \n",
    "\n",
    "---\n",
    "\n",
    "- 定义一般目标：整体目标和任务。\n",
    "- 定义执行工具：可以访问的所有工具的简短列表或“用户手册”。\n",
    "- 定义如何使用不同规划模块：详细说明不同规划模块的实用性以及在何种情况下使用哪些模块。\n",
    "- 定义相关记忆：这是一个动态部分，在推理时从用户的历史对话中找出最相关的记忆项目。可以通过用户提出的问题来确定“相关性”。\n",
    "- 定义人设（可选）：这个人设描述通常用于使模型更喜欢使用某些类型的工具或在最终回应中增加特殊性。\n",
    "\n",
    "\n",
    "```\n",
    "template = GENERAL INSTRUCTIONS\n",
    "\n",
    "Your task is to answer questions. If you cannot ansswer the question, request a\n",
    "helper or use a tool. Fill with Nil where no tool or helper is required.\n",
    "\n",
    "AVAILABLE TOOLS\n",
    "Search Tool\n",
    "Math Tool\n",
    "\n",
    "AVAILABLE HELPERS\n",
    "Decomposition: Breaks Complex Questions down into simplesubparts\n",
    "\n",
    "CONTEXTUAL INFORMATION\n",
    "<No previousquestions asked>\n",
    "\n",
    "QUESTION\n",
    "How much did the revenue grow between Q1 of 2024 annd Q2 of 2024?\n",
    "\n",
    "ANSWER FORMAT\n",
    "\"Tool_Request\": \"<Fill>\", \"Helper_Request \"<Fill>\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c5477-5927-4b13-b04f-ee925273b738",
   "metadata": {},
   "source": [
    "### Planning:\n",
    "\n",
    "\n",
    "- plan formulation and plan reflection. Two effective methods for incorporating feedback in planning are ReAct and Reflexion.\n",
    "- Task Decomposition (cot, tot,  LLM+P) and Self-Reflection (ReAct, Reflexion, Chain of Hindsight, Algorithm Distillation)\n",
    "\n",
    "---\n",
    "\n",
    "- 计划制定和计反思。在规划中整合反馈的两种有效方法是ReAct和Reflexion。\n",
    "- 任务分解（cot、tot、LLM+P）和自我反思（ReAct、Reflexion、回顾链、蒸馏）\n",
    "\n",
    "\n",
    "#### without feedback\n",
    "\n",
    "The planning module helps to break down the necessary steps or subtasks the agent will solve individually to answer the user request. \n",
    "\n",
    "\n",
    "规划模块帮助Agent将需要解决的必要步骤或子任务分解为单独的部分，以回答用户的请求。\n",
    "\n",
    "\n",
    "![](task-decomposition.webp)\n",
    "\n",
    "#### with feedback\n",
    "\n",
    "Enables the model to iteratively reflect and refine the execution plan based on past actions and observations.\n",
    "\n",
    "The goal is to correct and improve on past mistakes which helps to improve the quality of final results. \n",
    "\n",
    "This is particularly important in complex real-world environments and tasks where trial and error are key to completing tasks. \n",
    "\n",
    "---\n",
    "\n",
    "使模型能够基于过去的行动和观察，迭代地反思和完善执行计划。\n",
    "\n",
    "目标是纠正和改进过去的错误，从而提高最终结果的质量。\n",
    "\n",
    "在复杂的现实世界环境和任务中，特别重要，试错是完成任务的关键。\n",
    "\n",
    "\n",
    "##### react\n",
    "\n",
    "Integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. \n",
    "\n",
    "通过将行为空间扩展为特定任务的离散行动和语言空间的组合，将推理和行动整合到LLM中。\n",
    "\n",
    "\n",
    "![](react.png)\n",
    "\n",
    "\n",
    "##### reflexion\n",
    "\n",
    "\n",
    "Standard RL setup, the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. \n",
    "\n",
    "\n",
    "标准的强化学习，奖励模型提供简单的二元奖励，行动空间遵循ReAct中的设置，其中特定任务的行动空间通过语言扩展，以实现复杂的推理步骤。\n",
    "\n",
    "\n",
    "![](reflexion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f13329-ca89-46d1-8d89-c256cfff2ee2",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "\n",
    "- Sensory Memory\n",
    "- short-term\n",
    "- long-term\n",
    "\n",
    "---\n",
    "\n",
    "- 感觉记忆\n",
    "- 短期记忆\n",
    "- 长期记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a350706-3981-4820-a671-8caac3b68959",
   "metadata": {},
   "source": [
    "### Tool use\n",
    "\n",
    "connect with external environments to perform certain tasks.\n",
    "\n",
    "\n",
    "与外部环境连接以执行特定任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51719ef9",
   "metadata": {},
   "source": [
    "## What can LLM agents do?\n",
    "\n",
    "- Advanced problem solving\n",
    "- Self-reflection and improvemen: https://blog.langchain.dev/reflection-agents/\n",
    "- Tool use\n",
    "- Multi-agent framework: https://blog.langchain.dev/reflection-agents/\n",
    "\n",
    "---\n",
    "\n",
    "- 高级问题解决\n",
    "- 自我反思和改进：https://blog.langchain.dev/reflection-agents/\n",
    "- 工具使用\n",
    "- 多代理框架：https://blog.langchain.dev/reflection-agents/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123839d3",
   "metadata": {},
   "source": [
    "## LLM agent challenges\n",
    "\n",
    "- Limited context\n",
    "- Difficulty with long-term planning\n",
    "- Inconsistent outputs\n",
    "- Adapting to specific roles\n",
    "- Prompt dependence (try and trick)\n",
    "- Managing knowledge\n",
    "- Cost and efficiency\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- 有限的上下文\n",
    "- 长期规划困难\n",
    "- 输出不一致（不可靠、错误、不遵循指令等）\n",
    "- 适应特定角色\n",
    "- 依赖提示（尝试和技巧）\n",
    "- 知识管理\n",
    "- 成本和效率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512bbf8-5c6b-4324-b1cb-73826db4557e",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "- 你认为Agent的长期记忆和短期记忆应该怎么设计？\n",
    "- 请思考Human-in-the-Loop如何能应用在你的产品或设计中？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c3d83",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://www.superannotate.com/blog/llm-agents\n",
    "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
    "- https://developer.nvidia.com/blog/introduction-to-llm-agents/\n",
    "- https://www.promptingguide.ai/research/llm-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
